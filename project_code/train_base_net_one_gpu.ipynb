{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, splitext, basename\n",
    "import glob\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as trans\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import random\n",
    "import natsort\n",
    "import copy\n",
    "import collections\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os \n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine if your system supports CUDA\n",
    "print(\"==> Check devices..\")\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "\n",
    "#Also can print your current GPU id, and the number of GPUs you can use.\n",
    "print(\"Our selected device: \", torch.cuda.current_device())\n",
    "print(torch.cuda.device_count(), \" GPUs is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight balance sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WRSampler(dataset, wts):\n",
    "    each_data_wts = []\n",
    "    class_num_dict = dataset.class_num_dict\n",
    "    \n",
    "    for label in range(len(class_num_dict.keys())):\n",
    "        cls_num = class_num_dict[ dataset.label2name[label] ]\n",
    "        for i in range (cls_num):\n",
    "            each_data_wts.append(wts[label]/cls_num)\n",
    "    \n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(each_data_wts, len(each_data_wts), replacement=True)\n",
    "    \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plantdisease_Dataset(data.Dataset):\n",
    "    def __init__(self, image_dir, input_transform, is_train=False):\n",
    "        super(Plantdisease_Dataset, self).__init__()\n",
    "        \n",
    "        self.image_filenames = []\n",
    "        self.name2label = {}\n",
    "        self.label2name = {}\n",
    "        self.label = []\n",
    "        \n",
    "        path_pattern = image_dir + '/*'     \n",
    "        body_part = glob.glob(path_pattern, recursive=True)\n",
    "        self.class_num_dict = {}\n",
    "        \n",
    "        lab = 0\n",
    "        for cls in body_part:\n",
    "            self.class_num_dict[cls.split('/')[-1]] = 0\n",
    "            self.name2label[cls.split('/')[-1]] = lab\n",
    "            self.label2name[lab] = cls.split('/')[-1]\n",
    "            \n",
    "            image_list = glob.glob(cls + '/*')\n",
    "            for image in image_list:\n",
    "                self.class_num_dict[cls.split('/')[-1]] += 1\n",
    "                self.image_filenames.append(image)\n",
    "                self.label.append(lab)\n",
    "                \n",
    "            lab += 1                \n",
    "                \n",
    "\n",
    "        self.input_transform = input_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            input_file = self.image_filenames[index]\n",
    "        except:\n",
    "            print('error:', index)\n",
    "        img = Image.open(input_file)\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        if self.input_transform is not None:\n",
    "            img = self.input_transform(img)\n",
    "        label = self.label[index]\n",
    "  \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def images(self):\n",
    "        return self.image_filenames\n",
    "    \n",
    "    def class_num_dict(self):\n",
    "        return self.class_num_dict\n",
    "    \n",
    "    def name2label(self):\n",
    "        return self.name2label\n",
    "    \n",
    "    def classes(self):\n",
    "        return list(self.class_num_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, max_epoch, train_loader, validation_loader, config):\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    training_accuracy = []\n",
    "    validation_accuracy = []\n",
    "    total = 0\n",
    "    min_val_loss = 0.0\n",
    "    min_val_error = 0.0\n",
    "    early_stop_timer = 0 \n",
    "    current_best_model = None\n",
    "    \n",
    "    for epoch in range(max_epoch):  # loop over the dataset multiple times\n",
    "        train_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        correct_train = 0\n",
    "        correct_validation = 0\n",
    "        train_num = 0\n",
    "        val_num = 0\n",
    "        train_img_num = 0\n",
    "        validation_img_num = 0\n",
    "\n",
    "\n",
    "        ########################\n",
    "        # train the model      #\n",
    "        ########################\n",
    "\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "            #change the type into cuda tensor \n",
    "            \n",
    "            inputs = inputs.to(device) \n",
    "            labels = labels.to(device) \n",
    "            \n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # select the class with highest probability\n",
    "            _, pred = outputs.max(1)\n",
    "            # if the model predicts the same results as the true\n",
    "            # label, then the correct counter will plus 1\n",
    "            correct_train += pred.eq(labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "            train_num += 1\n",
    "            train_img_num += len(labels)\n",
    "\n",
    "\n",
    "        ########################\n",
    "        # validate the model   #\n",
    "        ########################\n",
    "\n",
    "        model.eval()\n",
    "        for i, (inputs, labels) in enumerate(validation_loader, 0):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            \n",
    "            inputs = inputs.to(device) \n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(inputs)\n",
    "            _, pred = outputs.max(1)\n",
    "            correct_validation += pred.eq(labels).sum().item()\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # update average validation loss \n",
    "            validation_loss += loss.item()\n",
    "            val_num += 1\n",
    "            validation_img_num += len(labels)\n",
    "\n",
    "\n",
    "        if epoch % 1 == 0:    # print every 200 mini-batches\n",
    "            val_error = 1 - correct_validation / validation_img_num\n",
    "            print('[%d, %5d] train_loss: %.3f' % (epoch, max_epoch, train_loss / train_num))\n",
    "            print('[%d, %5d] validation_loss: %.3f' % (epoch, max_epoch, validation_loss / val_num))\n",
    "            print('%d epoch, training accuracy: %.4f' % (epoch, correct_train / train_img_num))\n",
    "            print('%d epoch, validation accuracy: %.4f' % (epoch, correct_validation / validation_img_num))\n",
    "\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_val_error = val_error\n",
    "                current_best_model = model\n",
    "                print('Current best.')\n",
    "\n",
    "            if val_error < min_val_error:\n",
    "                min_val_error = val_error\n",
    "                config.best_epoch = epoch\n",
    "                early_stop_timer = 0\n",
    "                current_best_model = model\n",
    "                print('Current best.')\n",
    "            else:\n",
    "                early_stop_timer += 1\n",
    "                if early_stop_timer >= config.early_stop:\n",
    "                    torch.save(current_best_model.state_dict(), os.path.join(config.model_ouput_dir, \n",
    "                                                                             config.model_name + '_' + \n",
    "                                                                             str(config.best_epoch) + '.pth'))\n",
    "                    model = current_best_model\n",
    "                    print('Early Stop.\\n Best epoch is', str(config.best_epoch))\n",
    "                    break\n",
    "                    \n",
    "            t_loss.append(train_loss / train_num)\n",
    "            training_accuracy.append(correct_train / train_img_num)\n",
    "            validation_accuracy.append(correct_validation / validation_img_num)\n",
    "            running_loss = 0.0\n",
    "            validation_loss = 0.0\n",
    "            train_num = 0\n",
    "            val_num = 0\n",
    "            correct_train = 0\n",
    "            correct_validation = 0\n",
    "            total = 0\n",
    "            print('-----------------------------------------')\n",
    "\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.folder_names2code = {}\n",
    "        self.image_size = 256\n",
    "        self.early_stop = 3\n",
    "        self.max_epoch = 1000\n",
    "        self.train_batchsize = 16\n",
    "        self.eva_val_batchsize = 16\n",
    "        self.class_num = 15\n",
    "        self.each_class_item_num = {}\n",
    "        self.temperature = 1\n",
    "        self.alpha = 0.5\n",
    "        \n",
    "        \n",
    "        self.train_dataset_path = r'train'\n",
    "        self.validation_dataset_path = r'validation'\n",
    "        self.test_dataset_path = r'test'\n",
    "        self.model_ouput_dir = './models/'\n",
    "        self.best_epoch = 0\n",
    "        self.model_name = 'densenet121_Aug'\n",
    "        '''\n",
    "        class_folder_name = listdir(self.test_dataset_path)\n",
    "        self.class_folder_num = {}\n",
    "        for cf in class_folder_name:\n",
    "            self.class_folder_num[cf] = len(listdir(self.test_dataset_path + '/' + cf))\n",
    "        '''\n",
    "        self.net = 'resnet18'  # 0: resnet18\n",
    "        self.pretrain = False\n",
    "        \n",
    "        self.wts = [500 for i in range(15)]\n",
    "                    \n",
    "        self.lr = 0.0001\n",
    "        self.criterion = nn.CrossEntropyLoss() #定義損失函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgAugTransform():\n",
    "    def __init__(self, config=Config()):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Scale((config.image_size, config.image_size)),\n",
    "            iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
    "            iaa.Sometimes(0.25,\n",
    "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),  # 對batch中的一部分圖片應用一部分Augmenters,剩下的圖片應用另外的Augmenters。\n",
    "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)  # 即修改色調和飽和度\n",
    "        ])\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function (start training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "    transform_train = trans.Compose([\n",
    "        ImgAugTransform(config),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    transform_validation = trans.Compose([\n",
    "        trans.Resize((config.image_size, config.image_size)),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    transform_test = trans.Compose([\n",
    "        trans.Resize((config.image_size, config.image_size)),\n",
    "        trans.ToTensor(),\n",
    "        trans.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = Plantdisease_Dataset(image_dir=config.train_dataset_path, input_transform = transform_validation)\n",
    "    val_dataset = Plantdisease_Dataset(image_dir=config.validation_dataset_path, input_transform = transform_validation)\n",
    "    test_dataset = Plantdisease_Dataset(image_dir=config.test_dataset_path, input_transform = transform_test)\n",
    "    \n",
    "    # sampler = WRSampler(train_dataset, config.wts)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config.train_batchsize, shuffle=True)\n",
    "    validation_dataloader = DataLoader(dataset=val_dataset, batch_size=config.eva_val_batchsize, shuffle=False)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config.eva_val_batchsize, shuffle=False)\n",
    "\n",
    "    # net = torch.load('models/164.pth')\n",
    "    net = models.densenet121(pretrained=config.pretrain)\n",
    "    net.fc = nn.Sequential(nn.Linear(1024,512),nn.LeakyReLU(),nn.Linear(512,128),nn.LeakyReLU(),nn.Linear(128,config.class_num))\n",
    "    net = net.to(device)\n",
    "    \n",
    "    learning_rate = config.lr\n",
    "    max_epoch = config.max_epoch\n",
    "    criterion = config.criterion\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, betas=[0.9, 0.999]) #定優化函數\n",
    "    \n",
    "    train_micro(net, criterion, optimizer, max_epoch, train_dataloader, validation_dataloader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, evaluation_dataset, evaluation_loader, config):\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    test_num = 0\n",
    "    correct_top3 = 0\n",
    "    cls = np.zeros(config.class_num)\n",
    "    avg = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(evaluation_loader, 0):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(inputs)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct_test += pred.eq(labels).sum().item()\n",
    "        _, top3 = outputs.topk(3)\n",
    "        correct_top3 += top3.eq(labels.view(-1,1).expand_as(top3)).sum().item()\n",
    "        \n",
    "        for j in range(config.class_num):\n",
    "            cls[j] += (pred.eq(j) * pred.eq(labels)).sum().item()\n",
    "\n",
    "    print('Test set: Top 1 Accuracy: %d/%d (%.2f%%), Top 3 Accuracy: %d/%d (%.2f%%)' \n",
    "          % (correct_test, len(evaluation_dataset), correct_test / len(evaluation_dataset)*100, correct_top3, len(evaluation_dataset),\n",
    "             correct_top3/ len(evaluation_dataset)*100))\n",
    "    \n",
    "    class_num_dict = evaluation_dataset.class_num_dict\n",
    "    name2label = evaluation_dataset.name2label\n",
    "    classes = evaluation_dataset.classes\n",
    "    \n",
    "    for key in class_num_dict.keys():\n",
    "        print('%-20s : %d/%d    %10f%%' % (key, cls[name2label[key]], class_num_dict[key],\n",
    "                                            cls[name2label[key]]/class_num_dict[key]*100))\n",
    "        avg.append(cls[name2label[key]]/class_num_dict[key]*100) \n",
    "\n",
    "\n",
    "    print('Average per case accuracy: %10f%%' % (sum(avg)/len(avg)))\n",
    "    print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "transform_test = trans.Compose([\n",
    "    trans.Resize((config.image_size, config.image_size)),\n",
    "    trans.ToTensor(),\n",
    "    trans.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = Plantdisease_Dataset(image_dir=config.test_dataset_path, input_transform = transform_test)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=config.eva_val_batchsize, shuffle=False)\n",
    "\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('Reload')\n",
    "print('-----------------------------------------')\n",
    "# net = torch.load('./models/Macro.pth')\n",
    "net = models.resnet101(False)\n",
    "net.fc = nn.Sequential(nn.Linear(2048,512),nn.LeakyReLU(),nn.Linear(512,128),nn.LeakyReLU(),nn.Linear(128,config.class_num))\n",
    "state_dict = torch.load(r'./models/resnet101_raw_12.pth', map_location='cpu')\n",
    "net.load_state_dict(state_dict)\n",
    "#net = torch.load('./models/Enas_macro_10.pth')\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(net, test_dataset, test_dataloader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameter and MACs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "\n",
    "input = torch.randn(1, 3, 256, 256).cuda()\n",
    "macs, params = profile(net, inputs=(input,))\n",
    "\n",
    "print('{} {} {}'.format('Total params :','%f' % (params/1000000),'M') )\n",
    "print('{} {} {}'.format('Total macs :','%f' % (macs/1000000),'M') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
